{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "정보보호 4팀_ 웹공격탐지.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "c823e32c24d06b3518059b5f5e11ccae729689482027ea5186dc849db7650ef7"
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit ('torch': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyUaAVxDPQHZ"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4FsG6OcPQHe"
      },
      "source": [
        "파싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mujG_ApBPQHg"
      },
      "source": [
        "def parsing(path):#파싱을 진행하는 함수\n",
        "    with open(path,'r',encoding='utf-8') as f:\n",
        "        #파일을 읽어들이고 ['로그','로그',...] 이런식으로 로그를 구조화\n",
        "        train = []\n",
        "        log_data = \"\" # 하나의 로그에 대해 추출한 url path와 query, payload 값을 \" \"로 구분한 긴 문자열\n",
        "        para=\"\" # 하나의 로그에 대해 모든 내용을 담고 있는 문자열\n",
        "        while True:\n",
        "            l = f.readline() #한줄씩 읽어 옵니다\n",
        "            if not l:\n",
        "                break #파일을 전부 읽으면 읽기를 중단합니다.\n",
        "\n",
        "            if l != \"\\n\":\n",
        "                para +=l\n",
        "                if l[:4] == 'GET ' or l[:4] == 'PUT ':\n",
        "                    # GET method나 PUT method일 경우 url의 path와 query 추출\n",
        "                    url = l[4:len(l)-10]\n",
        "                    # url 은 method type과 HTTP/1.1을 뺀 중간 부분\n",
        "                    url_path = url[21:]\n",
        "                    # url에서 domain인 http://localhost:8080 제거 \n",
        "                    query_start = url_path.find('?')\n",
        "                    if (query_start != -1):\n",
        "                        # query 문이 있을 경우 path와 query들을 분리\n",
        "                        log_data += url_path[:query_start] + \" \"\n",
        "                        log_data += \" \".join(url_path[query_start+1:len(url)].split(\"&\")) + \" \"\n",
        "                    else:\n",
        "                        # query 문이 없을 경우 path 만 저장\n",
        "                        log_data += url_path + \" \"   \n",
        "\n",
        "                elif l[:5] == 'POST ':\n",
        "                    # POST method일 경우 url의 path 추출\n",
        "                    url = l[5:len(l)-10]\n",
        "                    url_path = url[21:]\n",
        "                    log_data += url_path + \" \"\n",
        "                                          \n",
        "            else:\n",
        "                if para!='':\n",
        "                    if para[:4]=='POST' or para[:3] == 'PUT': #Method가 POST나 PUT일 경우 예외적으로 바디까지 가져옵니다.\n",
        "                        log_data += \" \".join(f.readline().strip().split(\"&\")) + \" \"\n",
        "                    # print(log_data)\n",
        "                    train.append(log_data)\n",
        "                    para=\"\"\n",
        "                    log_data =\"\"\n",
        "                    # print(\"=============================================\")\n",
        "    return train"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbo4XsESPQHh"
      },
      "source": [
        "def dataset(path,mod='train'): #데이터셋을 생성합니다. 파싱한 데이터와 라벨을 생성합니다 \n",
        "    x = parsing(f'{path}norm_{mod}.txt') # mod에 따라 train을 가져올지 test 데이터를 가져올지 결정됩니다.\n",
        "    y = [0]*len(x)\n",
        "    x += parsing(f'{path}anomal_{mod}.txt')\n",
        "    y += [1]*(len(x)-len(y))\n",
        "    return x, y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSFNVOTMPQHi"
      },
      "source": [
        "def vectorize(train_x,test_x): #문장을 벡터로 만듭니다 해당 코드에서는 기본적인 tf idf를 사용하고 있습니다.\n",
        "    tf = TfidfVectorizer(min_df=0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(3,3))\n",
        "    tf = tf.fit(train_x)\n",
        "    train_vec = tf.transform(train_x)\n",
        "    test_vec = tf.transform(test_x)\n",
        "    return train_vec,test_vec"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqiXaTynPQHi"
      },
      "source": [
        "def train(train_vec,train_y): #Linear svm으로 훈련 시킵니다.\n",
        "    linear_svm = LinearSVC()\n",
        "    linear_svm.fit(train_vec, train_y)\n",
        "    return linear_svm"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox8t2ROpPQHj"
      },
      "source": [
        "def test(test_y,test_vec, svm): #입렵 받은 테스트와 모델로 테스트를 실시합니다\n",
        "    pred = svm.predict(test_vec)\n",
        "    print(accuracy_score(test_y,pred))\n",
        "    print(f1_score(test_y,pred))\n",
        "    return pred"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LPMi06lPQHk",
        "outputId": "441ce6f9-34a4-40aa-fc3c-5df5f072b788"
      },
      "source": [
        "############### 실행 코드 #######################\n",
        "################################################\n",
        "train_x, train_y = dataset('./','train')\n",
        "test_x, test_y =  dataset('./','test')\n",
        "train_vec, test_vec = vectorize(train_x, test_x)\n",
        "svm = train(train_vec, train_y)\n",
        "pred = test(test_y,test_vec, svm)\n",
        "\n",
        "# ########################################################\n",
        "# tf = TfidfVectorizer()\n",
        "# tf = tf.fit(train_x)\n",
        "\n",
        "# print(len(tf.vocabulary_)) # 고유한 단어가 대략 3만개가 나옵니다\n",
        "\n",
        "# print(tf.transform(train_x)[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9922214034225825\n",
            "0.9904800080168353\n"
          ]
        }
      ]
    }
  ]
}